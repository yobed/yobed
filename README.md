### ____

* *[github.com/yobed/local-llm]* **"Local LLM w/ RAG implementation"**
* This project was a journey into local LLMs and RAG (ran using `deepseek-r1:7b` for the LLM, and `nomic-embed-text` for embeddings. I used LangChain community and data from my [github.com/yobed/wsb] wallstreebets sentiment data.
* I did a deep dive into understanding how RAG works (embeddings, vector storage, searches, cosine similarity, etc), and how it is implemented, allowing for context within the LLM model.

* *[github.com/yobed/wsb]* *"r/wallstreetbets sentiment analysis"*
* This project processes r/wallstreetbets data, uses LLMs for sentiment analysis, and shows these findings with stock market trends.
* It's interesting to look at volume and sentiment throughout those years, as well as validating LLMs for reasoning fields -- the LLM will display it's reason for sentiment.


